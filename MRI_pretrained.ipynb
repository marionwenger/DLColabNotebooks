{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1HZxJCHgEwIxzB8MIR0emV3wa0nCxrXIQ",
      "authorship_tag": "ABX9TyMx0Wr//XZKn1qO1YEQ0tDm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marionwenger/DLColabNotebooks/blob/main/MRI_pretrained.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "# '/content/drive/MyDrive/DLforMRI'\n",
        "# save files on drive or locally, they are deleted in colab after 12 hours at the latest"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cQT8Q9-PGaj",
        "outputId": "cd73a4a6-4d53-4605-bfb2-05515ee272bf"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install split-folders"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pEBbFqDgSArX",
        "outputId": "d364d7a7-518d-4e9b-9004-d1a184db1871"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: split-folders in /usr/local/lib/python3.10/dist-packages (0.5.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "4gxZKoX11jM8"
      },
      "outputs": [],
      "source": [
        "# copy from Nicola's resnet18-model notebook\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import copy # A module that provides functions for creating copies of objects, useful for avoiding unintended modifications to variables.\n",
        "import os # A module that provides a way to interact with the operating system, allowing for tasks such as file and directory manipulation.\n",
        "import torch\n",
        "from PIL import Image # A module from the Python Imaging Library (PIL) that provides functionality for opening, manipulating, and saving various image file formats.\n",
        "from torch.utils.data import Dataset # A PyTorch class that represents a dataset and provides an interface for accessing and processing the data during training.\n",
        "import torchvision\n",
        "import torchvision.transforms.v2 as transforms # A module from the torchvision library that provides common image transformations, such as resizing, cropping, and normalization.\n",
        "# v2 is recommended and gets udpates\n",
        "from torch.utils.data import random_split # A function from PyTorch that allows for randomly splitting a dataset into training and validation subsets.\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau # A PyTorch scheduler that adjusts the learning rate during training based on a specified metric, reducing it when the metric plateaus.\n",
        "import torch.nn as nn # A module in PyTorch that provides classes for defining and building neural networks.\n",
        "from torchvision import utils # A module from torchvision that contains utility functions for working with images, such as saving and visualizing them.\n",
        "from torchvision.datasets import ImageFolder\n",
        "import splitfolders\n",
        "from torchsummary import summary\n",
        "import torch.nn.functional as F\n",
        "import pathlib\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir(r'/content/drive/MyDrive/DLforMRI/Brain Tumor Data')\n",
        "\n",
        "# ['MRI files', 'metadata.csv', '.DS_Store']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZOsN0WsUdlR",
        "outputId": "ca2e81bb-720c-4762-dc8a-da42c6811e7e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['MRI files', 'metadata.csv', '.DS_Store']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Path\n",
        "data_path_original = pathlib.Path(r'/content/drive/MyDrive/DLforMRI/Brain Tumor Data')\n",
        "\n",
        "# Splitting dataset to train_set, val_set and test_set\n",
        "splitfolders.ratio(data_path_original, output='MRI splitted', seed=1404, ratio=(0.6, 0.3, 0.1), move=True)\n",
        "# set move=True if you want to move the files instead of copying.\n",
        "\n",
        "# New dataset path\n",
        "data_path_splitted = pathlib.Path(r'/content/drive/MyDrive/DLforMRI/Brain Tumor Data/MRI splitted')\n",
        "\n",
        "os.listdir(r'/content/drive/MyDrive/DLforMRI/Brain Tumor Data/MRI splitted')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        },
        "id": "M6Smkj7qQNNS",
        "outputId": "b13f331d-37d4-41d0-a452-095eb3e16400"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "The input data is not in a right format. Within your folder \"/content/drive/MyDrive/DLforMRI/Brain Tumor Data/MRI files\" there are no directories. Consult the documentation how to the folder structure should look like.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-1b7f3ccc9c22>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Splitting dataset to train_set, val_set and test_set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0msplitfolders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mratio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path_original\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'MRI splitted'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1404\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmove\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m# set move=True if you want to move the files instead of copying.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/splitfolders/split.py\u001b[0m in \u001b[0;36mratio\u001b[0;34m(input, output, seed, ratio, group_prefix, move)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"`ratio` should\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m     \u001b[0mcheck_input_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muse_tqdm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/splitfolders/split.py\u001b[0m in \u001b[0;36mcheck_input_format\u001b[0;34m(input)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0mdirs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist_dirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m     64\u001b[0m             \u001b[0;34mf'The input data is not in a right format. Within your folder \"{input}\" there are no directories. Consult the documentation how to the folder structure should look like.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         )\n",
            "\u001b[0;31mValueError\u001b[0m: The input data is not in a right format. Within your folder \"/content/drive/MyDrive/DLforMRI/Brain Tumor Data/MRI files\" there are no directories. Consult the documentation how to the folder structure should look like."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "meta_data = pd.read_csv(r'/content/drive/MyDrive/DLforMRI/Brain Tumor Data/metadata.csv')\n",
        "meta_data.head()\n"
      ],
      "metadata": {
        "id": "1RXRX4GaQBhi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define transformation\n",
        "transform = transforms.Compose(\n",
        "    [\n",
        "        transforms.Resize((256,256)),\n",
        "        transforms.RandomHorizontalFlip(p=0.5),\n",
        "        transforms.RandomVerticalFlip(p=0.5),\n",
        "        transforms.RandomRotation(30),\n",
        "        transforms.ToTensor() #,\n",
        "        #transforms.Normalize(mean = [0.485, 0.456, 0.406],std = [0.229, 0.224, 0.225]) # Z-Transformation für die 3 Input-Channels\n",
        "        # denke brauche keine Normalisation hier und falls doch, wäre es besser, die mean udn std zu kennen...\n",
        "        ]\n",
        ")"
      ],
      "metadata": {
        "id": "jVyXphWSdb0o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform the train and validation data in their respective folders\n",
        "train_set = torchvision.datasets.ImageFolder(data_path_splitted.joinpath(\"train\"), transform=transform)\n",
        "train_set.transform\n",
        "val_set = torchvision.datasets.ImageFolder(data_path_splitted.joinpath(\"val\"), transform=transform)\n",
        "val_set.transform\n",
        "\n"
      ],
      "metadata": {
        "id": "lG41FYnEg62q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import and load train, validation\n",
        "batch_size = 16\n",
        "# https://www.mdpi.com/2079-9292/12/4/964\n",
        "# The research study concluded that batch sizes between 2 and 32 produced good results and added that small batch sizes are more robust than high batch sizes.\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size = batch_size, shuffle = True, num_workers = 2)\n",
        "val_loader = torch.utils.data.DataLoader(val_set, batch_size = batch_size, shuffle = True, num_workers = 2)"
      ],
      "metadata": {
        "id": "7e49M7BDhMgF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print shape for Training data and Validation data\n",
        "for key, value in {'Training Data': train_loader, \"Validation Data\": val_loader}.items():\n",
        "    for X, Y in value:\n",
        "        print(f\"{key}:\")\n",
        "        print(f\"Shape of X : {X.shape}\")\n",
        "        print(f\"Shape of Y : {Y.shape}\")\n",
        "        print(f\"Type  of Y : {Y.dtype}\")\n",
        "        break"
      ],
      "metadata": {
        "id": "iw8Wkv5xi4nI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "efficientnet_model = hub.KerasLayer(\"https://www.kaggle.com/models/google/bit/frameworks/TensorFlow2/variations/m-r101x1/versions/1\",\n",
        "                                 trainable=False,\n",
        "                                 input_shape=(28, 28, 3),\n",
        "                                 name='efficientnet')\n",
        "\n",
        "X_train_tensor_rgb = tf.image.grayscale_to_rgb(X_train_tensor)\n",
        "X_test_tensor_rgb = tf.image.grayscale_to_rgb(X_test_tensor)\n",
        "\n",
        "model_5 = Sequential([\n",
        "    efficientnet_model,\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model_5.compile(loss=CategoricalCrossentropy(),\n",
        "                optimizer=Adam(),\n",
        "                metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "wG6SaSJMsOSG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_5 = model_5.fit(x=X_train_tensor_rgb,\n",
        "                        y=y_train_tensor,\n",
        "                        steps_per_epoch=100,\n",
        "                        epochs=15,\n",
        "                        validation_data=(X_test_tensor_rgb, y_test_tensor),\n",
        "                        callbacks=[scheduler],\n",
        "                        verbose=0)"
      ],
      "metadata": {
        "id": "aaEicCKDsVZS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_lr_model_5 = get_best_learning_rate(history_5)\n",
        "print(best_lr_model_5)"
      ],
      "metadata": {
        "id": "HU_1_fexsV9M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "odel_6 = clone_model(model_5)\n",
        "\n",
        "model_6.compile(loss=CategoricalCrossentropy(),\n",
        "                optimizer=Adam(best_lr_model_5),\n",
        "                metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "HByv6NZysZ2J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensorboard_callback_efficientnet_model = create_tensorboard_callbacks('efficientnet_model')\n",
        "\n",
        "history_6 = model_6.fit(x=X_train_tensor_rgb,\n",
        "                        y=y_train_tensor,\n",
        "                        epochs=10,\n",
        "                        validation_data=(X_test_tensor_rgb, y_test_tensor),\n",
        "                        batch_size=32,\n",
        "                        callbacks=[tensorboard_callback_efficientnet_model, early_stopping])"
      ],
      "metadata": {
        "id": "5-qo1w7Usnui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_6.summary()"
      ],
      "metadata": {
        "id": "SjeIxzh7soWF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_6.evaluate(x=X_test_tensor_rgb, y=y_test_tensor, steps=len(X_test_tensor))"
      ],
      "metadata": {
        "id": "YSUGtMiRssDI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_result_model(history_6)"
      ],
      "metadata": {
        "id": "CRHUtydeswpI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nIFyX6Wzs0gk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}